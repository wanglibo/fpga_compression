// CS259 HLS friendly deflate implementation
// Created by Libo Wang, 5/26/15

#include "zlib.h"
#include "constant.h"
#include <string.h>
#include <stdint.h>
#include <stdio.h>
#include <assert.h>
// step 0: construct test pipeline
//   test.sh -- check (5/27)
// step 1: extract, save and use a custom huffman tree;
//   dump huffman tree to file - check (5/27)
//   dump huffman tree to header -- check (5/28)
//   build tree by hacking LZ77 results: all 1 to all fields -- check (5/28)
//     Effect of hack: slightly larger code (compression ratio reduces
//     from 3.507 to 3.495 in the original file. More to measure.
//   build simple lookup function from "compress_block" -- check (5/28)
// step 2: huffman bin packing in parallel
//   SW pipeline construction -- check (5/29)
//   batch binary alignment + packing -- check (6/1)
//   SW preprocessing of tree -- check (6/2)
//   functional test -- check (6/2)
// step 3: implement parallel LZ77 and verify output
//   Design hash table lookup routine -- check (6/3)
//   Parallel match selection -- check (6/3)
//   Local and cross window match filtering -- check (6/4), v2
//     Functional test shows the following compression ratios:
//        VEC (max match length)         Compression ratio
//                8                          2.496
//                16                         3.227
//                32                         3.741
// TODO step 4: HLS implementation + II=1 optimization
//   Reduce loop carried dependencies
//   (encountered bug: failed building synthesis data model
//     when using memcpy from input to output.)
//   II optimization of Huffman encoding -- check (6/8)
//   II optimization of LZ77  -- check (6/10), reverted to MS memory hierarchy
//             compression ratio dropped from 3.227 to 2.820.
//   Construct SDAccel project (6/11)
// TODO: optional:
//   Count L and D freq using our algorithm, then generate new huffman tree --
//     (not priority, non-blocking, try if time allows)

// parameters:
//   input[IN]: input buffer to read from, size bounded to 64kB.
//     must be a multiple of LOCAL_BUFSIZE to facilitate prefetching.
//   inlen[IN]: number of bytes in the input buffer; bounded by 64kB-10
//   tree[IN]: the buffer that contains the compressed huffman tree. It should be
//     the same tree as in huffman_tree.h. Generated by the software using example
//     SAM file, under original LZ77 implementation. Caller should load this from
//     a file that only contains the tree.
//   tree_len[IN]: The length of huffman tree in bits; we want to later write the
//     tree first to the output, and pack compressed data immediately after it.
//   output[OUT]: output buffer to write to
//   outLen[OUT]: number of output bytes, bounded to 64kB-10
//

#if 0
static uint512 input_b[1024];  // 64 KB, input upper bound
static uint512 output_b[2048]; // 128 KB, output upper bound
static uint512 tree_b[4];      // A huffman tree cannot exceed 64 * 4 bytes.
#else
static vec_t input_b[1024*64/VEC];  // 64 KB, input upper bound
static vec2_t output_b[1024*128/(2*VEC)]; // 128 KB, output upper bound
static vec2_t tree_b[4*64/(2*VEC)];      // A huffman tree cannot exceed 64 * 4 bytes.
#endif

void max_reduction(unsigned short input[VEC], unsigned short *max, 
  unsigned short *max_i) {
#pragma HLS INLINE off
  unsigned i;
  unsigned short maxv, maxi;
#if VEC==32
  unsigned short red16[16];
  unsigned short red16i[16];
#pragma HLS ARRAY_PARTITION variable=red16 complete
#pragma HLS ARRAY_PARTITION variable=red16i complete
#endif
  unsigned short red8[8];
  unsigned short red4[4];
  unsigned short red2[2];
  unsigned short red8i[8];
  unsigned short red4i[4];
  unsigned short red2i[2];
#pragma HLS ARRAY_PARTITION variable=red8 complete
#pragma HLS ARRAY_PARTITION variable=red4 complete
#pragma HLS ARRAY_PARTITION variable=red2 complete
#pragma HLS ARRAY_PARTITION variable=red8i complete
#pragma HLS ARRAY_PARTITION variable=red4i complete
#pragma HLS ARRAY_PARTITION variable=red2i complete
  maxv = 0;
  maxi = VEC;
#if VEC>=16
#if VEC==32
  for (i=0; i<16; i++) {
    unsigned short l, r, li, ri;
    l = input[2*i]; r = input[2*i+1]; li = 2*i; ri = 2*i+1;
    if(r > l) {
      red16[i] = r; red16i[i] = ri;
    } else {
      red16[i] = l; red16i[i] = li;
    }
  }
#endif

  for (i=0; i<8; i++) {
    unsigned short l, r, li, ri;
#if VEC==32
    l = red16[2*i]; r = red16[2*i+1]; li = red16i[2*i]; ri = red16i[2*i+1];
#else
    l = input[2*i]; r = input[2*i+1]; li = 2*i; ri = 2*i+1;
#endif
    if(r > l) {
      red8[i] = r; red8i[i] = ri;
    } else {
      red8[i] = l; red8i[i] = li;
    }
  }
  for (i=0; i<4; i++) {
    unsigned short l, r, li, ri;
    l = red8[2*i]; r = red8[2*i+1]; li = red8i[2*i]; ri = red8i[2*i+1];
    if(r > l) {
      red4[i] = r; red4i[i] = ri;
    } else {
      red4[i] = l; red4i[i] = li;
    }
  }
  for (i=0; i<2; i++) {
    unsigned short l, r, li, ri;
    l = red4[2*i]; r = red4[2*i+1]; li = red4i[2*i]; ri = red4i[2*i+1];
    if(r > l) {
      red2[i] = r; red2i[i] = ri;
    } else {
      red2[i] = l; red2i[i] = li;
    }
  }
  if (red2[1] > red2[0]) {
    maxv = red2[1]; maxi = red2i[1];
  } else {
    maxv = red2[0]; maxi = red2i[0];
  }
#else
  for (i=0; i<VEC; i++) {
    if (i==0 || input[i] > maxv) {
      maxv = input[i];
      maxi = i;
    }
  }
#endif
  *max = maxv; *max_i = maxi;
}

//int dump = 0;

// Perform bit packing on position i of local pack array.
void accumulate_pos(unsigned s_pos[4*VEC], unsigned i, unsigned out_iter,
    unsigned hcode[VEC*4], unsigned short *pack_p, unsigned short *pack_next_p) 
{
  unsigned j;
  unsigned short pack, pack_next;
  pack = 0; pack_next = 0;
  for (j=0; j<4*VEC; j++) {
    unsigned char upper = ((s_pos[j]+1) % (VEC) == i);
    // should write lower part here
    unsigned char lower = (s_pos[j] % (VEC) == i);

    unsigned char use_next = (s_pos[j] / (VEC) > out_iter) ||
        (upper && ((s_pos[j] + 1) / (VEC)) > out_iter);
    unsigned short val = upper ? (hcode[j] >> 16) : (lower ? hcode[j] : 0);
    pack |= use_next ? 0 : val;
    pack_next |= use_next ? val : 0;
/*
    if (dump==0) {
        // huffman encoding dump
        if (val) {
          if (upper) {
            fprintf(stderr, "Position %d has upper of data %d -- %08x\n",
                i, j, hcode[j]);
          }
          if (lower) {
            fprintf(stderr, "Position %d has lower of data %d -- %08x\n",
                i, j, hcode[j]);
          } 
        }
        if (use_next && val) {
          fprintf(stderr, "boundary: position %d, code %d\n", i, j);
        }
    }
*/
  }
  *pack_p = pack;
  *pack_next_p = pack_next;
}

// void complete_packing(unsigned hcode[VEC*4], unsigned pos[4*VEC],
//     pack,next

void deflate259(uint512* input, unsigned* in_len_p0, uint512* tree,
  unsigned* tree_len_p0, uint512* output, unsigned* out_len)
{
#pragma HLS INTERFACE m_axi port=input offset=slave bundle=gmem depth=1024
#pragma HLS INTERFACE m_axi port=in_len_p0 offset=slave bundle=gmem1 depth=1
#pragma HLS INTERFACE m_axi port=tree offset=slave bundle=gmem depth=8
#pragma HLS INTERFACE m_axi port=tree_len_p0 offset=slave bundle=gmem1 depth=1
#pragma HLS INTERFACE m_axi port=output offset=slave bundle=gmem depth=2048
#pragma HLS INTERFACE m_axi port=out_len offset=slave bundle=gmem1 depth=1
#pragma HLS INTERFACE s_axilite port=input bundle=control
#pragma HLS INTERFACE s_axilite port=in_len_p0 bundle=control
#pragma HLS INTERFACE s_axilite port=tree bundle=control
#pragma HLS INTERFACE s_axilite port=tree_len_p0 bundle=control
#pragma HLS INTERFACE s_axilite port=out_len bundle=control
#pragma HLS INTERFACE s_axilite port=output bundle=control
#pragma HLS INTERFACE s_axilite port=return bundle=control
  int i, j, iter, out_iter, iter0;
  unsigned input_pos = 0, output_pos = 0, base = 0, input_pos0;
  unsigned in_len = *in_len_p0;
  unsigned tree_len = *tree_len_p0;
  // Input double buffer
  vec_t data_window[2];
  vec_t lookahead;

  // Output double buffer
  vec2_t buffero1;
  vec2_t buffero2;

  unsigned char current_buffer = 1;
  unsigned char current_buffero = 1;
  unsigned char flip_output;

  // Point to the first position after the last valid match.
  unsigned short head_match_pos = 0;

  // LZ77 output
  unsigned short larray[VEC];
#pragma HLS ARRAY_PARTITION variable=larray complete
  unsigned short darray[VEC];
#pragma HLS ARRAY_PARTITION variable=darray complete
  unsigned char  ldvalid[VEC];

  // Huffman lookup output: (CODE, LENGTH) pairs.
  unsigned hcode[VEC*4];
  unsigned hlen[VEC*4];
#pragma HLS ARRAY_PARTITION variable=hcode complete
#pragma HLS ARRAY_PARTITION variable=hlen complete

  uint128 hcode_r[VEC];
  uint128 hlen_r[VEC];
#pragma HLS ARRAY_PARTITION variable=hcode_r complete
#pragma HLS ARRAY_PARTITION variable=hlen_r complete

  uint128 hcode_256, hlen_256;

  // Starting bit position of each code.
  unsigned pos[4*VEC];
#pragma HLS ARRAY_PARTITION variable=pos complete 
  unsigned s_pos[4*VEC];
#pragma HLS ARRAY_PARTITION variable=s_pos complete 

  // Compressed and packed data -- ready to send to output. Use double buffering
  // to reduce stall.
  // We know lcode, lextra, dcode, dextra's huffman codes are no more than 16 
  // bits, therefore it's impossible in one iteration to use up both buffers.
  unsigned short local_pack[VEC];
#pragma HLS ARRAY_PARTITION variable=local_pack complete
  unsigned short local_pack_next[VEC];
#pragma HLS ARRAY_PARTITION variable=local_pack_next complete

  unsigned bit_pos = 0;
  iter = 0;
  reset_history();
  huffman_translate(256, 0, &hcode_256, &hlen_256);
/*
  for (i=0; i<2*VEC; i++) {
    buffero1[i] = 0;
    buffero2[i] = 0;
  }
*/
  buffero1 = 0;
  buffero2 = 0;

#ifdef COUNT_FREQ
  reset_freq();
#endif

  // Bytes in the tree that are ready to move, which happens to be floor(tree_len)
  unsigned tree_bytes_floor = tree_len / 8;
  unsigned tree_bytes_ceil = (tree_len + 7) / 8;

  // input batch count
  unsigned input_b_count = (in_len + 63) / 64;
  unsigned tree_b_count = (tree_bytes_ceil + 63) / 64;

  // Copy data from DRAM
#if 0
  memcpy((void*) input_b, (void*) input, input_b_count * 64);
  memcpy((void*) tree_b, (void*) tree, tree_b_count * 64);

  vec_t* input_v = (vec_t*)input_b;
  vec2_t* output_v = (vec2_t*)output_b;
  vec2_t* tree_v = (vec2_t*)tree_b;
#else
  uint512 tmp512;
#pragma HLS array partition variable=input_b cyclic factor=4
  for (i=0; i<input_b_count; i++)
  {
#pragma HLS pipeline
     int j;
     tmp512 = input[i];
     for (j=0; j<64/VEC; j++) {
       input_b[(64/VEC)*i+j] = apint_get_range(tmp512, (j+1)*8*VEC-1, j*8*VEC);
     }
  }

#pragma HLS array partition variable=tree_b cyclic factor=4
  for (i=0; i<tree_b_count; i++)
  {
     int j;
#pragma HLS pipeline
     tmp512 = tree[i];
     for (j=0; j<64/(2*VEC); j++) {
       tree_b[(64/(2*VEC)*i+j)] =
           apint_get_range(tmp512, (j+1)*16*VEC-1, j*16*VEC);
     }
     //tree_b[2*i]   = apint_get_range(tmp512, 255, 0);
     //tree_b[2*i+1] = apint_get_range(tmp512, 511, 256);
  }

  vec_t* input_v = input_b;
  vec2_t* output_v = output_b;
  vec2_t* tree_v = tree_b;
#endif

  // Write the tree to output as much as possible; We write in multiple of
  // 4 * VEC * 2 bytes or 4 * VEC * 16 bits; the rest will be put into the current
  // huffman packing buffer.

  //unsigned tree_move = tree_bytes_floor / (VEC * 2) * (VEC * 2);
  unsigned tree_move = tree_bytes_floor / (VEC * 2);
  for (i=0; i<tree_move; i++) {
    output_v[i] = tree_v[i];
  }
  //fprintf(stderr, "Printed %d bytes from tree.\n", tree_move);
  output_pos += tree_move * 2 * VEC;
  fprintf(stderr, "Copied %d bytes from tree to output\n", output_pos);
  if (tree_bytes_ceil > output_pos) {
    //memcpy((void*) buffero1, (void*)(tree + tree_move), (tree_bytes_ceil - tree_move));
    buffero1 = tree_v[tree_move];
  }
  bit_pos = tree_len;

  //memcpy((void*)(data_window + VEC), (void*)(input), VEC);
  data_window[1] = input_v[0];
  do {
#pragma HLS PIPELINE II=1
#pragma HLS inline region recursive
    iter0 = iter;
    input_pos0 = input_pos;

    // Prepare for the next batch 
    if (input_pos + VEC < in_len+1) {
      input_pos += VEC;
    } else {
      input_pos = in_len+1;
    }
    iter++;

    // Shift lookahead value
    data_window[0] = data_window[1];
    // Wide in narrow out reg
    unsigned char data_window_c[VEC*2];
    vec_t lookahead = 0;
    if (in_len > ((1 + iter0) * VEC)) {
      lookahead = input_v[iter0 + 1];
      //memcpy((void*)(data_window+VEC), (void*)(input + (iter0 + 1) * VEC), VEC);
    }
//    *(vec_t*)(data_window_c) = data_window[0];
//    *(vec_t*)(data_window_c+VEC) = lookahead;
    vec_t2chars(data_window_c, data_window[0]);
    vec_t2chars(data_window_c+VEC, lookahead);
    // Store lookahead value
    data_window[1] = lookahead;

    /*
    for (i=0; i<VEC; i++) {
      data_window[i] = data_window[i+VEC];
    }
    */
    // Bring in lookahead data if available

#ifdef LZ77
    // Parallel LZ77 encoding
    match_window(data_window_c, input_pos0, in_len, larray, darray);

    // Compute a tail match to send to the next iteration as "head" match.
    unsigned short reach[VEC];
#pragma HLS ARRAY_PARTITION variable=reach complete
    unsigned short max_reach = 0;
    unsigned short max_reach_index = VEC;
    // First we compute the how far each match / literal can reach
    for (i=0; i<VEC; i++) {
      if (darray[i] != 0) {
        // cannot exceed input_pos + 2 * VEC - 1: within next window.
        reach[i] = i + larray[i] + 3;
      } else {
        reach[i] = i + 1;
      }
    }
    // Then from these reaches, extract the farmost one not overlapping
    // with the current match.
    unsigned short old_head_match_pos = head_match_pos;

    unsigned short reach_1[VEC][VEC];
#pragma HLS ARRAY_PARTITION variable=reach_1 complete
    for (i=0; i<VEC; i++) {
      for (j=0; j<VEC; j++) {
        if (j>=i) {
          reach_1[i][j] = reach[j];
        } else {
          reach_1[i][j] = 0;
        }
      }
    }

    unsigned short max_reaches[VEC];
    unsigned short max_reach_indices[VEC];
#pragma HLS ARRAY_PARTITION variable=max_reaches complete
#pragma HLS ARRAY_PARTITION variable=max_reach_indices complete

    // Update first valid position in the next batch. max_reach is guaranteed
    // to be no less than VEC. Trim the best match to avoid head overlap.
    for (i=0; i<VEC; i++) {
      max_reduction(&reach_1[i][0], max_reaches+i, max_reach_indices+i);
    }

    // Although we attempted reduction, we still can't overcome the critical path
    // delay on loop carried register "head_match_pos" by a frustrating 0.01 ns.
    // To pacify the compiler and ourselves, speculate all possible tails and
    // reduce critical path delay to O(1) instead of O(log(VEC)) for better scalability.
    // max_reaches[i] is the best reach into the next window when old_head_match_pos
    // is i.
    max_reach = max_reaches[old_head_match_pos];
    max_reach_index = max_reach_indices[old_head_match_pos];
/*

    if (max_reach_index < old_head_match_pos) {
      max_reach_index = old_head_match_pos;
    }
    // If trimmed match is shorter than 3 chars, reduce to last char.
    if (max_reach - max_reach_index < 3) {
      max_reach = VEC;
      max_reach_index = VEC-1;
    }
*/
    head_match_pos = max_reach - VEC;

    // Perform pipelined match selection: set valid bit for all matches.
    // Pass 1: Eliminate any matches that (1) extend beyond last match starting
    // position; (2) already handled by last cycle; (3) already handles by
    // the last match. Can be performed in parallel.
    for (i=0; i<VEC; i++) {
      if (i < old_head_match_pos || i > max_reach_index) {
        ldvalid[i] = 0;
      } else if (i == max_reach_index) {
        ldvalid[i] = 1;
      } else {
        // Trim a match it it overlaps with the final match
        if (darray[i] != 0 && reach[i] > max_reach_index) {
          unsigned short trimmed_len = larray[i] + 3 + max_reach_index - reach[i];
          if (trimmed_len < 3) {
            larray[i] = data_window_c[i];
            darray[i] = 0;
          } else {
            larray[i] = trimmed_len - 3;
          }
        }
        ldvalid[i] = 1;
      }
    }

    unsigned short processed_len = old_head_match_pos;
    // Pass 2: For all the remaining matches, filter with lazy evaluztion.
    for (i=0; i<VEC-1; i++) {
      // Make sure we don't touch the tail match 
      if (ldvalid[i] && i != max_reach_index) {
        if (i < processed_len) {
          ldvalid[i] = 0;
        } else if (darray[i] == 0) { // literal should be written out
          processed_len++;
        } else { // current position is a match candidate
          // When the next match is better: commit literal here instead of match
          if (ldvalid[i+1] && darray[i+1] > 0 && larray[i+1] > larray[i]) {
            larray[i] = data_window_c[i];
            darray[i] = 0;
            processed_len++;
          } else {
            processed_len += larray[i] + 3;
          }
        }
      }
    }
/*
    // DUMP LZ77 outputs
    fprintf(stderr, "Data window:\n");
    for (i=0; i<2*VEC; i++) {
      fprintf(stderr, "%02x ", data_window_c[i]);
    }
    fprintf(stderr, "\n");
    for (i=0; i<VEC; i++) {
      fprintf(stderr, "Pos %d, (L,D) = (%d(0x%x),%d) reach=%d V=%d\n", input_pos0+i, larray[i], 
          larray[i], darray[i], reach[i], ldvalid[i]);
    }
    fprintf(stderr, "old_head = %d, max_reach = %d\n", old_head_match_pos, max_reach);

    // LZ77 integrity check
    processed_len = old_head_match_pos;
    for (i=0; i<VEC; i++) {
      if (i < old_head_match_pos) assert(ldvalid[i]==0);
      else if (i > max_reach_index) assert(ldvalid[i]==0);
      else if (i == max_reach_index) {
        assert(ldvalid[i]==1);
        if (darray[i] == 0) assert(i==VEC-1 && max_reach==VEC);
      }
      else {
        if (i < processed_len) assert(ldvalid[i]==0);
        else {
          assert(ldvalid[i]==1);
          if (darray[i]==0) processed_len++;
          else processed_len += larray[i] + 3;
        }
      }
    }
*/
#else // No LZ77

    for (i=0; i<VEC; i++) {
      if (input_pos0 + i < in_len) {
        larray[i] = data_window_c[i];
        darray[i] = 0;
        ldvalid[i] = 1;
      } else {
        ldvalid[i] = 0;
      }
    }
#endif
    // parallel huffman encoding.
    for (i=0; i<VEC; i++) {
      huffman_translate(larray[i], darray[i], &hcode_r[i], &hlen_r[i]);
    }

    uint128 hcode_rp, hlen_rp;
    // Wide in narrow out local buffer to facilitate partition of hcode and hlen.
    unsigned hcode_rp32[4], hlen_rp32[4];
    for (i=0; i<VEC; i++) {
      if (input_pos0 + i < in_len && ldvalid[i]) {
//        *((uint128*)hcode_rp32) = hcode_r[i];
//        *((uint128*)hlen_rp32) = hlen_r[i];
        uint128_to_uint32(hcode_rp32, hcode_r[i]);
        uint128_to_uint32(hlen_rp32, hlen_r[i]);
      } else if (input_pos0 + i == in_len) {
//        *((uint128*)hcode_rp32) = hcode_256;
//        *((uint128*)hlen_rp32) = hlen_256;
        uint128_to_uint32(hcode_rp32, hcode_256);
        uint128_to_uint32(hlen_rp32, hlen_256);
      } else {
//        *((uint128*)hcode_rp32) = 0;
//        *((uint128*)hlen_rp32) = 0;
        uint128_to_uint32(hcode_rp32, 0);
        uint128_to_uint32(hlen_rp32, 0);
      }

      for (j=0; j<4; j++) {
        hcode[i*4+j] = hcode_rp32[j]; 
        hlen[i*4+j] = hlen_rp32[j]; 
      }
//      *((uint128*)(hcode + i*4)) = hcode_r[i];
//      *((uint128*)(hlen + i*4)) = hlen_r[i];
    }

    // Huffman packing.
    // Perform pre-shift just like Altera GZIP example algorithm, but put code
    // into a function to avoid unrolling of large loops.

    // Phase 1. Calculate starting bit pos of each of the 4*VEC codes.
    // Accumulation of bit offsets.
    pos[0] = 0;
    for (i=1; i<4*VEC; i++) {
      pos[i] = pos[i-1] + hlen[i-1];
    }

    unsigned old_bit_pos = bit_pos;
    unsigned new_bit_pos = pos[4*VEC-1] + hlen[4*VEC-1] + old_bit_pos;
    // bit pos is the register to carry through the loop so we update immediately
    bit_pos = new_bit_pos;
    //fprintf(stderr, "Batch %d starting bit pos: %d\n", iter0, old_bit_pos);

    // It turns out 2 * VEC bytes is a upper bound of output.
    // Proof: for a match, maximal bit length = max(lcode) + max(lextra) 
    //   + max(dcode) + max(dextra) = 13 + 5 + 11 + 13 = 42 < 48 = 6 bytes.
    // The match length is 3 at minimum.
    // For a literal, maximal bit length < 2 bytes = max(lcode).

    //if (new_bit_pos - old_bit_pos > VEC * 8 ) {
    //  fprintf(stderr, "Iter %d, output length = %d\n", iter, new_bit_pos - old_bit_pos);
    //}

    out_iter = old_bit_pos / (16 * VEC);

    for (i=0; i<4*VEC; i++) {
      pos[i] += old_bit_pos;
      s_pos[i] = pos[i] / 16;
    }

    // Phase 2. Shift each code by an appropriate amount and align to 16-bit
    // boundary.
    for (i=0; i<4*VEC; i++) {
      hcode[i] = hcode[i] << (pos[i] % 16);
    }
    for (i=0; i<VEC; i++) {
      local_pack[i] = 0;
      local_pack_next[i] = 0;
    }

    // Phase 3. For each position in the current and next packing buffer,
    // OR with appropriate data.
    for (i=0; i<VEC; i++) {
      accumulate_pos(s_pos, i, out_iter, hcode,
          &local_pack[i],
          &local_pack_next[i]);
    }

    flip_output = (new_bit_pos >= 16 * VEC * (out_iter+1));
    unsigned current_buffero0 = current_buffero;
    if (flip_output) {
      if (current_buffero == 1) current_buffero = 2;
      else current_buffero = 1;
    }

    // Use pack and pack_next for wide access.
    unsigned short pack[VEC];
    unsigned short pack_next[VEC];
    for (i=0; i<VEC; i++) {
      pack[i] = local_pack[i];
      pack_next[i] = local_pack_next[i];
    }
/*
    if (dump == 0) {
      dump = 1;
    for (i=0; i<VEC; i++) {
      fprintf(stderr, "%02x ", pack[i]);
    }
    fprintf(stderr, "\n");

    for (i=0; i<VEC; i++) {
      fprintf(stderr, "%02x ", pack_next[i]);
    }
    fprintf(stderr, "\n");
}
*/
  // Now pack current buffers into output double buffer
    if (current_buffero0 == 1) {
//      buffero1 |= *((vec2_t*)(pack));
//      buffero2 |= *((vec2_t*)(pack_next));
      buffero1 |= short2vec2_t(pack);
      buffero2 |= short2vec2_t(pack_next);
    } else {
//      buffero2 |= *((vec2_t*)(pack));
//      buffero1 |= *((vec2_t*)(pack_next));
      buffero2 |= short2vec2_t(pack);
      buffero1 |= short2vec2_t(pack_next);
    }

    // Once some data gets written in the next buffer, we should flush
    // the current buffer.

    // Flush the buffer if it's full
    if (flip_output) {
      //fprintf(stderr, "** flush\n");
      if (current_buffero0 == 1) {
        //memcpy((void*)(output + output_pos), (void*) buffero1, VEC*2);
        output_v[output_pos/(VEC*2)] = buffero1;
        buffero1 = 0;
/*
        unsigned char *b1 = (unsigned char*) &buffero1;
        fprintf(stderr, "wrote bytes from buffer 1: \n");
        for (i=0; i<VEC*2; i++) {
          fprintf(stderr, "%02x_", b1[i]);
        }
        fprintf(stderr, "\n");
        for (i=0; i<VEC*2; i++) {
          buffero1[i] = 0;
        }
*/
      } else {
//        memcpy((void*)(output + output_pos), (void*) buffero2, VEC*2);
        output_v[output_pos/(VEC*2)] = buffero2;
        buffero2 = 0;
/*
        fprintf(stderr, "wrote bytes from buffer 2: \n");
        for (i=0; i<VEC*2; i++) {
          fprintf(stderr, "%02x ", buffero2[VEC*2-1-i]);
        }
        fprintf(stderr, "\n");

        for (i=0; i<VEC*2; i++) {
          buffero2[i] = 0;
        }
*/
      }
      output_pos += VEC * 2;
    }

  } while (input_pos <= in_len); // Also allow equality for block finish code
                                 // (L=256)
  // Flush what's remaining in the output buffer
  unsigned bytes_left = ((bit_pos % (VEC * 16)) + 7) / 8;
//  fprintf(stderr, "final bitpos: %d, bytes left: %d\n", bit_pos, bytes_left);
  if (bit_pos % (VEC * 16) != 0) {
    if (current_buffero == 1) {
/*
      memcpy((void*)(output + output_pos), (void*)buffero1,
          bytes_left);
      fprintf(stderr, "wrote bytes from buffer 1: \n");
      for (i=0; i<bytes_left; i++) {
        fprintf(stderr, "%02x ", buffero1[bytes_left-1-i]);
      }
      fprintf(stderr, "\n");
*/
      output_v[output_pos/(VEC*2)] = buffero1;
    } else {
/*
      memcpy((void*)(output + output_pos), (void*)buffero2,
          bytes_left);
      fprintf(stderr, "wrote bytes from buffer 2: \n");
      for (i=0; i<bytes_left; i++) {
        fprintf(stderr, "%02x ", buffero2[bytes_left-1-i]);
      }
      fprintf(stderr, "\n");
*/
      output_v[output_pos/(VEC*2)] = buffero2;
    }
    output_pos += bytes_left;
  }
  *out_len = output_pos;

  unsigned output_b_count = (output_pos + 63) / 64;
  assert(output_b_count <= 2048);
#if 0
  memcpy((void*) output, (void*)output_b, output_b_count * 64);
#else
#pragma HLS array partition variable=output_b cyclic factor=4
  for (i=0; i<output_b_count; i++)
  {
#pragma HLS pipeline
     vec2_t tmpvec2;
     int j;
     for (j=0; j<64/(2*VEC); j++) {
       tmp512 = apint_set_range(tmp512, (j+1)*16*VEC-1, j*16*VEC,
           output_b[(64/(2*VEC))*i+j]);
     }
     //tmp512   = apint_set_range(tmp512, 255, 0, output_b[2*i]);
     //tmp512   = apint_set_range(tmp512, 511, 256, output_b[2*i+1]);
     output[i] = tmp512;
  }
#endif


#ifdef COUNT_FREQ
  dump_freq();
#endif
}
